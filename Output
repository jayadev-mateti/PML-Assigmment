library(caret)
> 
> #Reading the file into R#
> training<-read.csv("D:\\DDrive\\DSP\\Practical Machine Learning\\pml-training.csv",na.strings=c("#DIV/0!","","NULL","NA"))
> dim(training)
[1] 19622   160
> 
> #Removing coloumns with more missing values#
> training1<-training[,colSums(is.na(training))<19000]
> dim(training1)
[1] 19622    60
> 
> #Removing unwanted variables#
> remove = c("X","user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window")
> training2<-training1[,-which(names(training1) %in% remove)]
> dim(training2)
[1] 19622    53
> 
> #Seeing correlations between predictors#
> corrMatrix<-abs(cor(training2[,-53]))
> 
> #setting the correlations with self to zero
> diag(corrMatrix)=0
> 
> #Removing highly correlated variables#
> removecor<-which(corrMatrix>0.75,arr.ind=T)
> training3<-training2[,-removecor]
> dim(training3)
[1] 19622    20
> 
> 
> 
> #Dividing the traing set into training and test sets#
> inTrain = createDataPartition(y = training3$classe, p = 0.7, list = FALSE)
> train = training3[inTrain, ]
> test = training3[-inTrain, ]
> 
> #Running randomfores#
> model<-train(train$classe~.,data=train,method="rf",traincontrol=c(method="cv",number=4),ntree=100,importance=TRUE)
Loading required package: randomForest
randomForest 4.6-10
Type rfNews() to see new features/changes/bug fixes.
> model$finalModel

Call:
 randomForest(x = x, y = y, ntree = 100, mtry = param$mtry, importance = TRUE,      traincontrol = ..1) 
               Type of random forest: classification
                     Number of trees: 100
No. of variables tried at each split: 2

        OOB estimate of  error rate: 1.89%
Confusion matrix:
     A    B    C    D    E class.error
A 3893    6    3    4    0 0.003328213
B   48 2589   16    3    2 0.025959368
C    4   39 2330   21    2 0.027545910
D    1    2   68 2167   14 0.037744227
E    0    7    6   14 2498 0.010693069
> 
> #Seeing the importance of variables#
> varImp(model)
rf variable importance

  variables are sorted by maximum importance across the classes
                         A     B        C      D      E
roll_dumbbell       39.573 62.24 100.0000 67.808 53.534
magnet_dumbbell_z   82.259 94.18  82.8123 70.699 85.011
pitch_forearm       35.787 62.82  38.8979 90.137 62.782
roll_arm            41.530 85.38  58.8729 73.015 79.909
gyros_belt_z        37.530 68.87  58.2412 73.859 59.452
gyros_dumbbell_y    35.035 62.82  71.7190 50.443 50.564
yaw_arm             43.165 66.91  48.5460 53.113 45.567
accel_forearm_z     26.201 47.17  63.3945 31.332 43.544
gyros_forearm_x     13.442 57.14  33.6135 25.924 25.130
accel_forearm_x     13.441 39.73  39.8485 54.217 34.286
magnet_forearm_z    22.934 53.97  50.5230 41.830 36.488
roll_forearm        38.221 45.03  53.0072 34.817 42.064
gyros_belt_y        11.614 39.48  36.5684 51.500 47.993
pitch_arm           11.890 40.64  42.2029 25.323 16.520
yaw_forearm         24.226 38.64  40.6866 35.436 35.966
magnet_forearm_x    15.852 25.79  38.0327 22.484 24.269
total_accel_forearm 17.764 28.79  36.6854 22.745 35.175
total_accel_arm      0.000 29.90  22.1342 14.442 13.487
gyros_arm_z          2.034 19.89   0.6176  5.527  7.723
> 
> #Predicting the test observations and checking accuracy#
> pred<-predict(model,test)
> confusionMatrix(pred,test$classe)
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1668   28    1    0    0
         B    2 1102    9    1    1
         C    1    6 1012   27    4
         D    2    0    3  929    6
         E    1    3    1    7 1071

Overall Statistics
                                          
               Accuracy : 0.9825          
                 95% CI : (0.9788, 0.9857)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.9779          
 Mcnemar's Test P-Value : 3.727e-07       

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9964   0.9675   0.9864   0.9637   0.9898
Specificity            0.9931   0.9973   0.9922   0.9978   0.9975
Pos Pred Value         0.9829   0.9883   0.9638   0.9883   0.9889
Neg Pred Value         0.9986   0.9922   0.9971   0.9929   0.9977
Prevalence             0.2845   0.1935   0.1743   0.1638   0.1839
Detection Rate         0.2834   0.1873   0.1720   0.1579   0.1820
Detection Prevalence   0.2884   0.1895   0.1784   0.1597   0.1840
Balanced Accuracy      0.9948   0.9824   0.9893   0.9807   0.9937
> #Out of sample error is 1-.9825, so, 1.75%.I expected it to be more than OOB estimate(1.89%) but then it is almost same and in fact less#
#So, there is no question of over-fitting!#

> #Predicting the 20 validation cases#
> validation<-read.csv("D:\\DDrive\\DSP\\Practical Machine Learning\\pml-testing.csv",na.strings=c("#DIV/0!","","NULL","NA"))
> dim(validation)
[1]  20 160
> prediction<-predict(model,validation)
> prediction
 [1] C A B A A E D B A A B C B A E E A B B B
Levels: A B C D E
> 
